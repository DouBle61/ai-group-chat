# ===== AI ç¾¤èŠç³»ç»Ÿ - ç½‘é¡µç‰ˆï¼ˆæµå¼ä¼˜åŒ–ï¼‰ =====

import os
import json
from dotenv import load_dotenv
from openai import OpenAI
from flask import Flask, render_template, request, jsonify, Response, stream_with_context

load_dotenv()

app = Flask(__name__)

# ç¡…åŸºæµåŠ¨å®¢æˆ·ç«¯
api_key = os.getenv("SILICONFLOW_API_KEY")
client = OpenAI(
    api_key=api_key or "missing-key",
    base_url="https://api.siliconflow.cn/v1",
)

# å‚ä¸ç¾¤èŠçš„ AI ä»¬
AI_LIST = [
    {"name": "DeepSeek", "model": "deepseek-ai/DeepSeek-V3", "emoji": "ğŸ”µ", "color": "#4A90D9"},
    {"name": "KIMI", "model": "moonshotai/Kimi-K2-Instruct", "emoji": "ğŸŸ£", "color": "#9B59B6"},
    {"name": "æ™ºè°±", "model": "THUDM/GLM-4-9B-Chat", "emoji": "ğŸŸ¢", "color": "#2ECC71"},
    {"name": "åƒé—®", "model": "Qwen/Qwen3-8B", "emoji": "ğŸŸ ", "color": "#E67E22"},
]


def ask_ai(ai, conversation_text):
    """è®©æŸä¸ª AI åŸºäºå¯¹è¯å†å²å‘è¨€"""
    other_names = ", ".join(a["name"] for a in AI_LIST if a["name"] != ai["name"])
    response = client.chat.completions.create(
        model=ai["model"],
        messages=[
            {
                "role": "system",
                "content": (
                    f"ä½ æ˜¯{ai['name']}ï¼Œæ­£åœ¨ä¸€ä¸ªå¤šAIè®¨è®ºç¾¤é‡Œã€‚\n"
                    f"å…¶ä»–å‚ä¸è€…æœ‰ï¼š{other_names}\n"
                    f"è¯·é˜…è¯»å¯¹è¯å†å²ï¼Œç»™å‡ºä½ çš„ç‹¬ç‰¹è§‚ç‚¹ã€‚\n"
                    f"å¯ä»¥è¡¥å……ã€åé©³æˆ–èµåŒå…¶ä»–AIçš„è§‚ç‚¹ã€‚\n"
                    f"è¯·ä¿æŒç®€æ´ï¼Œç”¨ä¸­æ–‡å›ç­”ï¼Œä¸è¶…è¿‡150å­—ã€‚\n"
                    f"ä¸è¦é‡å¤åˆ«äººå·²ç»è¯´è¿‡çš„å†…å®¹ã€‚"
                ),
            },
            {"role": "user", "content": conversation_text},
        ],
        max_tokens=300,
    )
    return response.choices[0].message.content


@app.route("/")
def home():
    return render_template("index.html", ai_list=AI_LIST)


@app.route("/health")
def health():
    return jsonify({"status": "ok", "api_key_set": bool(api_key)})


@app.route("/chat", methods=["POST"])
def chat():
    """æµå¼å¤„ç†ï¼šæ¯ä¸ª AI å›ç­”å®Œç«‹åˆ»å‘é€ç»™å‰ç«¯"""
    data = request.json
    if not data or not data.get("question", "").strip():
        return jsonify({"error": "è¯·è¾“å…¥é—®é¢˜"}), 400

    question = data["question"].strip()
    rounds = data.get("rounds", 2)

    if not api_key:
        return jsonify({"error": "API Key æœªé…ç½®"}), 500

    def generate():
        chat_history = []
        chat_history.append({"speaker": "ç”¨æˆ·", "content": question})

        # å‘é€ç”¨æˆ·æ¶ˆæ¯
        user_msg = {"speaker": "ç”¨æˆ·", "content": question, "type": "user"}
        yield f"data: {json.dumps(user_msg, ensure_ascii=False)}\n\n"

        # æ ¼å¼åŒ–å†å²
        def format_history():
            return "\n\n".join(f"{m['speaker']}ï¼š{m['content']}" for m in chat_history)

        # å¤šè½®è®¨è®º
        for r in range(1, rounds + 1):
            # å‘é€è½®æ¬¡æ ‡è®°
            yield f"data: {json.dumps({'type': 'round', 'round': r}, ensure_ascii=False)}\n\n"

            for ai in AI_LIST:
                # å‘Šè¯‰å‰ç«¯è°åœ¨æ€è€ƒ
                yield f"data: {json.dumps({'type': 'thinking', 'speaker': ai['name'], 'emoji': ai['emoji']}, ensure_ascii=False)}\n\n"

                try:
                    answer = ask_ai(ai, format_history())
                    msg = {
                        "speaker": ai["name"],
                        "content": answer,
                        "type": "ai",
                        "emoji": ai["emoji"],
                        "color": ai["color"],
                        "round": r,
                    }
                    chat_history.append({"speaker": ai["name"], "content": answer})
                except Exception as e:
                    msg = {
                        "speaker": ai["name"],
                        "content": f"[å‘è¨€å¤±è´¥ï¼š{e}]",
                        "type": "error",
                        "emoji": ai["emoji"],
                        "color": ai["color"],
                        "round": r,
                    }
                    chat_history.append({"speaker": ai["name"], "content": msg["content"]})

                yield f"data: {json.dumps(msg, ensure_ascii=False)}\n\n"

        # æ€»ç»“
        yield f"data: {json.dumps({'type': 'summary_start'}, ensure_ascii=False)}\n\n"

        try:
            summary = client.chat.completions.create(
                model="deepseek-ai/DeepSeek-V3",
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "ä½ æ˜¯è®¨è®ºä¸»æŒäººï¼Œè¯·æ€»ç»“ä»¥ä¸‹è®¨è®ºï¼š\n"
                            "1. å„æ–¹çš„ä¸»è¦è§‚ç‚¹\n"
                            "2. å¤§å®¶çš„å…±è¯†\n"
                            "3. ä¸»è¦åˆ†æ­§\n"
                            "ç”¨ä¸­æ–‡å›ç­”ï¼Œä¸è¶…è¿‡200å­—ã€‚"
                        ),
                    },
                    {"role": "user", "content": format_history()},
                ],
                max_tokens=400,
            )
            msg = {
                "speaker": "ä¸»æŒäºº",
                "content": summary.choices[0].message.content,
                "type": "summary",
                "emoji": "ğŸ¯",
                "color": "#E74C3C",
            }
        except Exception as e:
            msg = {
                "speaker": "ä¸»æŒäºº",
                "content": f"æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼š{e}",
                "type": "error",
                "emoji": "ğŸ¯",
                "color": "#E74C3C",
            }

        yield f"data: {json.dumps(msg, ensure_ascii=False)}\n\n"
        yield "data: {\"type\": \"done\"}\n\n"

    return Response(
        stream_with_context(generate()),
        mimetype="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
        },
    )


if __name__ == "__main__":
    print("\n" + "=" * 50)
    print("   AI ç¾¤èŠç½‘é¡µç‰ˆå·²å¯åŠ¨ï¼")
    print("   æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼šhttp://127.0.0.1:5000")
    print("=" * 50 + "\n")
    app.run(debug=True)