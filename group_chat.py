# ===== AI ç¾¤èŠç³»ç»Ÿï¼ˆç¡…åŸºæµåŠ¨ç‰ˆï¼‰ =====

import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

# ç¡…åŸºæµåŠ¨å®¢æˆ·ç«¯
client = OpenAI(
    api_key=os.getenv("SILICONFLOW_API_KEY"),
    base_url="https://api.siliconflow.cn/v1",
)

# å‚ä¸ç¾¤èŠçš„ AI ä»¬
AI_LIST = [
    {"name": "ğŸ”µ DeepSeek", "model": "deepseek-ai/DeepSeek-R1"},
    {"name": "ğŸŸ£ KIMI", "model": "Pro/moonshotai/Kimi-K2.5"},
    {"name": "ğŸŸ¢ æ™ºè°±", "model": "Pro/zai-org/GLM-5"},
    {"name": "ğŸŸ  åƒé—®", "model": "Qwen/Qwen3-VL-32B-Thinking"},
    {"name": "ğŸŸ  è…¾è®¯", "model": "tencent/Hunyuan-A13B-Instruct"},
]

# å¯¹è¯å†å²
chat_history = []


def ask_ai(ai, conversation_text):
    """è®©æŸä¸ª AI åŸºäºå¯¹è¯å†å²å‘è¨€"""
    other_names = ", ".join(a["name"] for a in AI_LIST if a["name"] != ai["name"])

    response = client.chat.completions.create(
        model=ai["model"],
        messages=[
            {
                "role": "system",
                "content": (
                    f"ä½ æ˜¯{ai['name']}ï¼Œæ­£åœ¨ä¸€ä¸ªå¤šAIè®¨è®ºç¾¤é‡Œã€‚\n"
                    f"å…¶ä»–å‚ä¸è€…æœ‰ï¼š{other_names}\n"
                    f"è¯·é˜…è¯»å¯¹è¯å†å²ï¼Œç»™å‡ºä½ çš„ç‹¬ç‰¹è§‚ç‚¹ã€‚\n"
                    f"å¯ä»¥è¡¥å……ã€åé©³æˆ–èµåŒå…¶ä»–AIçš„è§‚ç‚¹ã€‚\n"
                    f"è¯·ä¿æŒç®€æ´ï¼Œç”¨ä¸­æ–‡å›ç­”ï¼Œä¸è¶…è¿‡150å­—ã€‚\n"
                    f"ä¸è¦é‡å¤åˆ«äººå·²ç»è¯´è¿‡çš„å†…å®¹ã€‚"
                ),
            },
            {"role": "user", "content": conversation_text},
        ],
        max_tokens=300,
    )
    return response.choices[0].message.content


def format_history():
    """æŠŠå¯¹è¯å†å²æ ¼å¼åŒ–æˆæ–‡å­—"""
    text = ""
    for msg in chat_history:
        text += f"{msg['speaker']}ï¼š{msg['content']}\n\n"
    return text


def group_chat(question, rounds=2):
    """ç¾¤èŠä¸»æµç¨‹"""
    print("\n" + "ğŸŸ¢" * 25)
    print("         AI ç¾¤èŠå¼€å§‹ï¼")
    print("ğŸŸ¢" * 25)
    print(f"\nå‚ä¸è€…ï¼š{' | '.join(a['name'] for a in AI_LIST)}")

    # è®°å½•ç”¨æˆ·çš„é—®é¢˜
    chat_history.append({"speaker": "ğŸ‘¤ ç”¨æˆ·", "content": question})
    print(f"\nğŸ‘¤ ç”¨æˆ·ï¼š{question}")

    # å¤šè½®è®¨è®º
    for r in range(1, rounds + 1):
        print("\n" + "=" * 50)
        print(f"ğŸ“¢ ç¬¬ {r} è½®è®¨è®º")
        print("=" * 50)

        for ai in AI_LIST:
            print(f"\n{ai['name']} æ­£åœ¨æ€è€ƒ...")
            try:
                answer = ask_ai(ai, format_history())
                chat_history.append({"speaker": ai["name"], "content": answer})
                print(f"{ai['name']}ï¼š{answer}")
            except Exception as e:
                error_msg = f"[å‘è¨€å¤±è´¥ï¼š{e}]"
                chat_history.append({"speaker": ai["name"], "content": error_msg})
                print(f"{ai['name']}ï¼š{error_msg}")

    # æœ€ç»ˆæ€»ç»“ï¼ˆç”¨ DeepSeek åšæ€»ç»“ï¼‰
    print("\n" + "=" * 50)
    print("ğŸ“‹ è®¨è®ºæ€»ç»“")
    print("=" * 50)

    try:
        summary = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯è®¨è®ºä¸»æŒäººï¼Œè¯·æ€»ç»“ä»¥ä¸‹è®¨è®ºï¼š\n"
                        "1. å„æ–¹çš„ä¸»è¦è§‚ç‚¹\n"
                        "2. å¤§å®¶çš„å…±è¯†\n"
                        "3. ä¸»è¦åˆ†æ­§\n"
                        "ç”¨ä¸­æ–‡å›ç­”ï¼Œä¸è¶…è¿‡200å­—ã€‚"
                    ),
                },
                {"role": "user", "content": format_history()},
            ],
            max_tokens=400,
        )
        print(f"\nğŸ¯ æ€»ç»“ï¼š{summary.choices[0].message.content}")
    except Exception as e:
        print(f"\nğŸ¯ æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼š{e}")

    print("\n" + "ğŸ”´" * 25)
    print("         AI ç¾¤èŠç»“æŸï¼")
    print("ğŸ”´" * 25)


# ===== å¯åŠ¨ç¾¤èŠ =====
if __name__ == "__main__":
    print("=" * 50)
    print("     æ¬¢è¿ä½¿ç”¨ AI ç¾¤èŠç³»ç»Ÿï¼")
    print("  DeepSeek | KIMI | æ™ºè°± | åƒé—®")
    print("=" * 50)

    question = input("\nè¯·è¾“å…¥ä½ æƒ³è®© AI ä»¬è®¨è®ºçš„é—®é¢˜ï¼š")
    rounds_input = input("è®¨è®ºï¿½ï¿½è½®ï¼Ÿï¼ˆç›´æ¥å›è½¦é»˜è®¤2è½®ï¼‰ï¼š")
    rounds = int(rounds_input) if rounds_input else 2

    group_chat(question, rounds)